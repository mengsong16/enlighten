# scene
scene_id: /home/meng/habitat-sim/data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
#scene_id: /home/meng/habitat-sim/data/replica/stages/frl_apartment_stage.glb
#scene_id: /home/meng/habitat-sim/data/replica/stages/Stage_v3_sc0_staging.glb
#scene_id: /dataset/mp3d/17DRP5sb8fy/17DRP5sb8fy.glb

# robot
agent_initial_position: [3, 0, 1]
agent_initial_rotation: [0, 70, 0] #[0, 90, 0]
forward_resolution: 0.25
rotate_resolution: 10

# observation space
color_sensor: true
depth_sensor: true
semantic_sensor: false
image_width: 224
image_height: 224
normalize_depth: false
min_depth: 0
max_depth: 1
dictionary_observation_space: true

# task
dark_mode: true
flashlight_z: 0.2
measurements: ['distance_to_goal', 'success', 'spl']


# goal
goal_conditioned: true
goal_format: pointgoal # imagegoal
goal_coord_system: polar  #  cartesian
goal_dimension: 2
goal_position: [4, 0, -1]
random_goal: true
random_start: false

# reward
success_distance: 0.2 # l2 distance in meter
success_reward: 2.5 
slack_reward: -1e-4
distance_to: "point" #view_points

# episode termination condition
max_steps_per_episode: 400
max_collisions_per_episode: 200

# neural network
visual_encoder: ResNet # CNN 
pretrained_visual_encoder: false  
pretrained_whole_model: false
# path to the saved whole model or visual encoder only
pretrained_model_path: data/ddppo-models/gibson-2plus-resnet50.pth
# Whether or not the visual encoder backbone will be trained
train_encoder: true

# sampling
use_double_buffered_sampler: false
num_steps: 128  # rollout buffer length

# vector env
num_environments: 6

# dataset
dataset_type: PointNav
split: train
dataset_path: "data/datasets/pointnav/gibson/v1/{split}/{split}.json.gz"
content_scenes: ["*"]
scenes_dir: "data/scene_datasets/"

# training
torch_gpu_id: 0
simulator_gpu_id: 0
seed: 1
# only one of them can be used
num_updates: 1000
total_num_steps: 100000   # 75e6
# checkpoint
# only one of them can be used
num_checkpoints: 10
checkpoint_interval: -1
checkpoint_folder: ""

# PPO
clip_param: 0.2
ppo_epoch: 4
num_mini_batch: 2
value_loss_coef: 0.5
entropy_coef: 0.01
lr: 2.5e-4
eps: 1e-5
max_grad_norm: 0.5           
hidden_size: 512
use_gae: true
gamma: 0.99
tau: 0.95
use_linear_clip_decay: true
use_linear_lr_decay: true
reward_window_size: 50
use_normalized_advantage: false


# evaluation
# do not save video if empty
# save to disk under video_path
eval_video_option: ["disk", "tensorboard"]
# if eval_checkpoint_file is an existing file in checkpoint_folder, eval single checkpoint
# otherwise, eval all checkpoints in checkpoint_folder
eval_checkpoint_file: ""
eval_use_ckpt_config: true
video_dir: "video_dir"
tensorboard_dir: ""
# Evaluate on all episodes
test_episode_count: -1


# distributed
# use distributed computation or not
force_distributed: true
# Append the slurm job ID to the resume state filename if running a slurm job
# This is useful when you want to have things from a different job but same
# same checkpoint dir not resume.
preemption_append_slurm_job_id: false
# Save resume states only when running with slurm
# This is nice if you don't want debug jobs to resume
preemption_save_state_batch_only: false
# Number of gradient updates between saving the resume state
preemption_save_resume_state_interval: 100
# The PyTorch distributed backend to use
distrib_backend: GLOO

# training stats and log
log_file: "train.log"
verbose: true
log_interval: 25  # log stats every n training updates
reward_window_size: 50 # compute stats every n episodes












